{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6b078027-a2e7-493b-87c3-577ba421b4b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# System\n",
    "import os\n",
    "import datetime\n",
    "\n",
    "# Data Analysis\n",
    "import re\n",
    "import matplotlib as mpl\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "# Machine Learning\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_regression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "42c54d53-8b7b-44c2-96fd-2257809c1097",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Analysis(object):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        cwd = os.getcwd()\n",
    "        kaggle = os.path.join(cwd,'kaggle')\n",
    "        \n",
    "        with open(os.path.join(kaggle,'data_description.txt'),'r') as f:\n",
    "            self.data_description = f.read()\n",
    "        self.df_input_train = pd.read_csv(os.path.join(kaggle,'train.csv'),header=0,index_col=0)\n",
    "        self.df_input_test = pd.read_csv(os.path.join(kaggle,'test.csv'),header=0,index_col=0).assign(SalePrice=0)\n",
    "        self.df_output_sample = pd.read_csv(os.path.join(kaggle,'sample_submission.csv'),header=0,index_col=0)\n",
    "        \n",
    "        self.preprocessor = None\n",
    "        self.predictor = None\n",
    "        \n",
    "        self.input_data = {'train':self.df_input_train,'test':self.df_input_test}\n",
    "        self.prediction_data = {'train': None,'test': None}\n",
    "        \n",
    "        self.df_output = None\n",
    "        self.output_file = os.path.join(cwd,'housing_analysis-tsj7ww-TrevorJordan.csv')\n",
    "        \n",
    "        self.topics = None\n",
    "        self.input_features = None\n",
    "        self.features = None\n",
    "        with open(os.path.join(cwd,'features.md'),'r') as f:\n",
    "            self.features_md = f.read()\n",
    "            f.close()\n",
    "    \n",
    "        self._get_features()\n",
    "    \n",
    "    def _get_features(self):\n",
    "        topics = {'House':[],'Lot':[],'Location':[],'Sale':[],'Target':[]}\n",
    "        features = {'all':[],'cat':[],'int':[],'target':[]}\n",
    "        \n",
    "        for line in self.features_md.split('\\n'):\n",
    "            if line[:3] == '###':\n",
    "                s = line.replace('### ','')\n",
    "                topic = re.sub(r'\\W+', '', s)\n",
    "            if line[:2] == '- ':\n",
    "                s = line.replace('- ','')\n",
    "                dtype = s.split('(')[1].split(')')[0]\n",
    "                feature = re.sub(r'\\W+', '', s.split('(')[0].strip())\n",
    "\n",
    "                topics[topic].append((topic,dtype,feature))\n",
    "                features['all'].append(feature)\n",
    "                features[dtype].append(feature)\n",
    "        \n",
    "        self.input_features = features\n",
    "        self.topics = topics\n",
    "    \n",
    "    def preprocess(self):\n",
    "        preprocessor = Preprocessor(self.input_data,self.input_features,self.topics)\n",
    "        self.preprocessor = preprocessor\n",
    "        preprocessor.combine()\n",
    "        preprocessor.clean()\n",
    "        preprocessor.dummy()\n",
    "        preprocessor.select()\n",
    "        preprocessor.normalize()\n",
    "        preprocessor.wrangle()\n",
    "        self.prediction_data = preprocessor.prediction_data\n",
    "        self.preprocessor = preprocessor\n",
    "        self.features = preprocessor.features\n",
    "    \n",
    "    def predict(self):\n",
    "        predictor = Predictor(self.prediction_data,self.features)\n",
    "        self.predictor = predictor\n",
    "        predictor.gbr()\n",
    "        predictor.knn()\n",
    "        predictor.ridge()\n",
    "        predictor.assess(predictor.model_gbr)\n",
    "        predictor.assess(predictor.model_knn)\n",
    "        predictor.assess(predictor.model_ridge)\n",
    "        # predictor.predict([predictor.model_gbr,predictor.model_knn,predictor.model_ridge])\n",
    "        predictor.df_output = predictor.df_output\n",
    "        self.predictor = predictor  \n",
    "    \n",
    "    def wrap_up(self):\n",
    "        self.df_output.to_csv(output_file,header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "e6f5a7ea-3fae-474a-849d-eb549faa880b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Preprocessor(object):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    def __init__(self,data,features,topics):\n",
    "        self.input_data = data\n",
    "        self.features = features\n",
    "        self.topics = topics\n",
    "        \n",
    "        self.data = None\n",
    "        self.prediction_data = {\n",
    "            'X': None,\n",
    "            'y': None,\n",
    "        }\n",
    "    \n",
    "    def combine(self):\n",
    "        dtypes = {}\n",
    "        for topic,columns in self.topics.items():\n",
    "            for col in columns:\n",
    "                if col[2]=='SalePrice':\n",
    "                    dtypes[col[2]] = int\n",
    "                elif col[1]=='int':\n",
    "                    dtypes[col[2]] = np.float32\n",
    "                elif col[1]=='cat':\n",
    "                    dtypes[col[2]] = object\n",
    "                else:\n",
    "                    object\n",
    "        df = pd.concat([\n",
    "            self.input_data['train'].assign(Segment='train'),\n",
    "            self.input_data['test'].assign(Segment='test')\n",
    "        ]).reset_index(drop=True).fillna(0).astype(dtype=dtypes)\n",
    "        \n",
    "        data = {}\n",
    "        data['y'] = df[['SalePrice','Segment']]\n",
    "        df = df.drop(['SalePrice'],axis=1)\n",
    "        data['X'] = df\n",
    "        self.data = data\n",
    "    \n",
    "    def clean(self):\n",
    "        None\n",
    "        \n",
    "    def dummy(self):\n",
    "        df = self.data['X']\n",
    "\n",
    "        dummies = pd.get_dummies(df[self.features['cat']])\n",
    "        df = (dummies\n",
    "              .join(df[\n",
    "                  ['Segment']+self.features['int']\n",
    "              ],how='inner')\n",
    "         )\n",
    "        self.data['dummied'] = df\n",
    "        self.features['dummies'] = list(dummies.columns)\n",
    "    \n",
    "    def select(self):\n",
    "        kbest = SelectKBest(score_func=f_regression, k=20)\n",
    "        X = self.data['dummied'].loc[self.data['dummied'].Segment=='train'].drop(['Segment'],axis=1)\n",
    "        y = self.data['y'].loc[self.data['y'].Segment=='train'].SalePrice\n",
    "        segment = self.data['dummied'].Segment\n",
    "        fit = kbest.fit(X,y)\n",
    "        selected = kbest.get_feature_names_out(kbest.feature_names_in_)\n",
    "        \n",
    "        self.data['selected'] = pd.DataFrame(\n",
    "            fit.transform(self.data['dummied'].drop(['Segment'],axis=1)),\n",
    "            columns=selected,\n",
    "            index=self.data['dummied'].index\n",
    "        ).join(segment,how='inner')\n",
    "        \n",
    "        self.features['selected'] = selected\n",
    "        for dtype,cols in self.features.items():\n",
    "            self.features[dtype] = [i for i in cols if i in selected]\n",
    "    \n",
    "    def normalize(self):\n",
    "        sc = StandardScaler()\n",
    "        normalized = pd.DataFrame(\n",
    "            sc.fit_transform(self.data['selected'][self.features['int']]),\n",
    "            columns=self.features['int'],index=self.data['selected'].index\n",
    "        )\n",
    "        self.data['normalized'] = normalized.join(self.data['selected'][['Segment']+self.features['dummies']],how='inner')\n",
    "    \n",
    "    def wrangle(self):\n",
    "        test = {\n",
    "            'X': self.data['normalized'].loc[self.data['normalized'].Segment=='test'].drop(['Segment'],axis=1),\n",
    "            'y': self.data['y'].loc[self.data['y'].Segment=='test'].drop(['Segment'],axis=1)\n",
    "        }\n",
    "        _ = {'X':None,'y':None}\n",
    "        train = {\n",
    "            'fit': _,\n",
    "            'score': _,\n",
    "        }\n",
    "        \n",
    "        (train['fit']['X'],train['score']['X'],\n",
    "        train['fit']['y'],train['score']['y']) = train_test_split(\n",
    "            self.data['normalized'].loc[self.data['normalized'].Segment=='train'].drop(['Segment'],axis=1),\n",
    "            self.data['y'].loc[self.data['y'].Segment=='train'].SalePrice,\n",
    "            test_size=0.2, random_state=42\n",
    "        )\n",
    "        \n",
    "        prediction_data = {'train':train,'test':test}\n",
    "        self.prediction_data = prediction_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "aab0a2d4-e185-4bc6-9c0c-a70a837ca10a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Predictor(object):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    def __init__(self,prediction_data,features):\n",
    "        self.prediction_data = prediction_data\n",
    "        self.features = features\n",
    "        \n",
    "        self.model_gbr = None\n",
    "        self.model_knn = None\n",
    "        self.model_ridge = None\n",
    "        \n",
    "        self.df_output = None\n",
    "    \n",
    "    def gbr(self):\n",
    "        gbr_params = {\n",
    "            'n_estimators': 1000,\n",
    "            'max_depth': 3,\n",
    "            'min_samples_split': 5,\n",
    "            'learning_rate': 0.01,\n",
    "            'loss': 'squared_error',\n",
    "        }\n",
    "        model_gbr = GradientBoostingRegressor(**gbr_params)\n",
    "        model_gbr.fit(**self.prediction_data['train']['fit'])\n",
    "        self.model_gbr = model_gbr\n",
    "        \n",
    "    def knn(self):\n",
    "        best = {'n':0,'corr':0,'mse':0,'model':None}\n",
    "        for n in range(20):\n",
    "            n+=1\n",
    "            model_knn = KNeighborsRegressor(n_neighbors=n)\n",
    "            model_knn.fit(**self.prediction_data['train']['fit'])\n",
    "            corr,mse = self.assess(model_knn,tune=True)\n",
    "            if best['corr'] < corr:\n",
    "                best = {'n':n,'corr':corr,'mse':mse,'model':model_knn}\n",
    "        print(best['n'])\n",
    "        self.model_knn = best['model']\n",
    "    \n",
    "    def ridge(self):\n",
    "        best = {'a':0,'corr':0,'mse':0,'model':None}\n",
    "        a = 0.3\n",
    "        for i in range(20):\n",
    "            a+=0.1\n",
    "            model_ridge = Ridge(alpha=a)\n",
    "            model_ridge.fit(**self.prediction_data['train']['fit'])\n",
    "            corr,mse = self.assess(model_ridge,tune=True)\n",
    "            if best['corr'] < corr:\n",
    "                best = {'a':a,'corr':corr,'mse':mse,'model':model_ridge}\n",
    "        print(best['a'])\n",
    "        self.model_ridge = model_ridge\n",
    "        \n",
    "    def assess(self,model,tune=False):\n",
    "        corr = model.score(**self.prediction_data['train']['score'])\n",
    "        mse = mean_squared_error(self.prediction_data['train']['score']['y'], model.predict(self.prediction_data['train']['score']['X']))\n",
    "        if tune:\n",
    "            return (corr,mse)\n",
    "        else:\n",
    "            print('Model Accuracy:',round(corr,4))\n",
    "            print(\"Model MSE on test set:\",round(mse,4))\n",
    "        \n",
    "    def predict(self,models):\n",
    "        preds = []\n",
    "        for model in models:\n",
    "            preds.append(model.predict(self.prediction_data['test']['X']))\n",
    "        pred = (sum(preds)/len(preds)).round(2)\n",
    "        print(pred)\n",
    "        self.prediction_data['test']['y'] = pred\n",
    "        self.df_output = pd.DataFrame(pred,columns=['SalePrice'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8266cab-b92f-4ea2-b5e1-17099667f591",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "785b0807-e1ba-484f-b370-eda96ac3d9d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "ed6b48f2-19f4-4c51-aec7-16c39b2152c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\trevs\\miniconda3\\lib\\site-packages\\pandas\\core\\algorithms.py:798: FutureWarning: In a future version, the Index constructor will not infer numeric dtypes when passed object-dtype sequences (matching Series behavior)\n",
      "  uniques = Index(uniques)\n",
      "C:\\Users\\trevs\\miniconda3\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:289: RuntimeWarning: invalid value encountered in true_divide\n",
      "  correlation_coefficient /= X_norms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "0.4\n",
      "Model Accuracy: 0.9627\n",
      "Model MSE on test set: 286105214.4248\n",
      "Model Accuracy: 0.9999\n",
      "Model MSE on test set: 514417.8082\n",
      "Model Accuracy: 0.8333\n",
      "Model MSE on test set: 1279016364.7886\n"
     ]
    }
   ],
   "source": [
    "analysis = Analysis()\n",
    "\n",
    "analysis.preprocess()\n",
    "analysis.predict()\n",
    "# analysis.wrap_up()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdcd7e02-5135-461f-9c90-f750198576c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a982219-46d2-46c4-984c-dfe4629733c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ad1c2bc-1613-4df5-8eb5-96b3bff828a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ab9ca81-7895-47f6-999d-e584239dd808",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d547d01-b4c6-4173-94ec-feadfc066c96",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5e03e7f-ef5c-4def-b2ca-2040aaf3f5b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "177a4ebd-96bf-48eb-968b-bfa099ca6180",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a357a67b-4f7d-487b-a9fc-6336b05ed8b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d36686f-59e3-41a7-aa34-9c84b272f782",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d667d7d5-5dc6-4fd0-88a3-8d8bb8625b9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Analyzer(object):\n",
    "    def __init__(self,df):\n",
    "        self.df = df\n",
    "    \n",
    "    def eda(self):\n",
    "        print(self.df.columns)\n",
    "       #print(self.df.head())\n",
    "        for cname,value in self.df.iloc[0,:].to_dict().items():\n",
    "            column = self.df.loc[:,cname]\n",
    "            print(cname,': ',value,type(value),len(column.unique()))\n",
    "            if len(column.unique()) < 20:\n",
    "                print(dict(column.value_counts()))\n",
    "        \n",
    "    def correlate(self):\n",
    "        None\n",
    "        \n",
    "    def plot(self):\n",
    "        None\n",
    "\n",
    "analyzer = Analyzer(analysis.df_input_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a455e684-0625-443b-81bf-94819d522290",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfa81e3a-9e16-4b5f-95bb-bbe26a586591",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2cbfb3f-d2ee-49a9-9000-c70ff5d2664e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd2b42b0-afd4-42d7-b78c-0073e094de39",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fa59400-a130-4abc-b680-b5b5cddf08ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39500df3-f830-4e53-b7a5-b7ad1dd106bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ab3b060-8085-46fd-90e7-55a8178196ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02c8260f-7682-4a10-aca4-54170ecf5230",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
